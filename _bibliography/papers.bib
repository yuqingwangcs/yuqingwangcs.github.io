---
---

@article{wang2023tram,
  abstract  = {Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper, we introduce TRAM, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate a comprehensive evaluation of the temporal reasoning capabilities of large language models (LLMs). We conduct an extensive evaluation using popular LLMs, such as GPT-4 and Llama2, in both zero-shot and few-shot learning scenarios. Additionally, we employ BERT-based models to establish the baseline evaluations. Our findings indicate that these models still trail human performance in temporal reasoning tasks. It is our aspiration that TRAM will spur further progress in enhancing the temporal reasoning abilities of LLMs.},
  title     = {TRAM: Benchmarking Temporal Reasoning for Large Language Models},
  author    = {Yuqing Wang and Yun Zhao},
  journal   = {arXiv preprint arXiv:2310.00835},
  year      = {2023},
  abbr      = {arXiv},
  arxiv     = {2310.00835},
  code      = {https://github.com/eternityyw/tram-benchmark},
  selected  = {true}
}

@article{wang2023metacognitive,
  abstract  = {In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. While recent research on prompting has enhanced the reasoning capabilities of LLMs, a gap remains in further improving their understanding abilities. In this study, we introduce Metacognitive Prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. Our experiments involve five prevalent LLMs: Llama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general natural language understanding (NLU) tasks from the GLUE and SuperGLUE benchmarks. Results indicate that, although GPT-4 consistently excels in most tasks, PaLM, when equipped with MP, approaches its performance level. Furthermore, across models and datasets, MP consistently outperforms existing prompting methods, including standard and chain-of-thought prompting. This study underscores the potential to amplify the understanding abilities of LLMs and highlights the benefits of mirroring human introspective reasoning in NLU tasks.},
  title     = {Metacognitive Prompting Improves Understanding in Large Language Models},
  author    = {Yuqing Wang and Yun Zhao},
  journal   = {arXiv preprint arXiv:2308.05342},
  year      = {2023},
  abbr      = {arXiv},
  arxiv     = {2308.05342},
  code      = {https://github.com/EternityYW/Metacognitive-Prompting},
  selected  = {true}
}

@phdthesis{wang2023ai,
  title     = {AI and Big Data in Health: Boosting Reliability and Efficiency in Predictive Healthcare Models},
  author    = {Yuqing Wang},
  year      = {2023},
  school    = {University of California, Santa Barbara},
  abbr      = {Dissertation},
  pdf       = {Yuqing_thesis.pdf}
}

@article{wang2023empirical,
  abstract  = {The Segment Anything Model (SAM) is a foundation model for general image segmentation. Although it exhibits impressive performance predominantly on natural images, understanding its robustness against various image perturbations and domains is critical for real-world applications where such challenges frequently arise. In this study we conduct a comprehensive robustness investigation of SAM under diverse real-world conditions. Our experiments encompass a wide range of image perturbations. Our experimental results demonstrate that SAM's performance generally declines under perturbed images, with varying degrees of vulnerability across different perturbations. By customizing prompting techniques and leveraging domain knowledge based on the unique characteristics of each dataset, the model's resilience to these perturbations can be enhanced, addressing dataset-specific challenges. This work sheds light on the limitations and strengths of SAM in real-world applications, promoting the development of more robust and versatile image segmentation solutions.},
  title     = {An Empirical Study on the Robustness of the Segment Anything Model (SAM)},
  author    = {Yuqing Wang and Yun Zhao and Linda Petzold},
  journal   = {arXiv preprint arXiv:2305.06422},
  year      = {2023},
  abbr      = {arXiv},
  arxiv     = {2305.06422},
  code      = {https://github.com/EternityYW/SAM-Robustness},
  selected  = {false}
}

@article{wang2023large,
  abstract  = {Large language models (LLMs) have made significant progress in various domains, including healthcare. However, the specialized nature of clinical language understanding tasks presents unique challenges and limitations that warrant further investigation. In this study, we conduct a comprehensive evaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within the realm of clinical language understanding tasks. These tasks span a diverse range, including named entity recognition, relation extraction, natural language inference, semantic textual similarity, document classification, and question-answering. We also introduce a novel prompting strategy, self-questioning prompting (SQP), tailored to enhance LLMs' performance by eliciting informative questions and answers pertinent to the clinical scenarios at hand. Our evaluation underscores the significance of task-specific learning strategies and prompting techniques for improving LLMs' effectiveness in healthcare-related tasks. Additionally, our in-depth error analysis on the challenging relation extraction task offers valuable insights into error distribution and potential avenues for improvement using SQP. Our study sheds light on the practical implications of employing LLMs in the specialized domain of healthcare, serving as a foundation for future research and the development of potential applications in healthcare settings.},
  title     = {Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding},
  author    = {Yuqing Wang and Yun Zhao and Linda Petzold},
  journal = {In Machine Learning for Healthcare Conference},
  year      = {2023},
  publisher = {PMLR},
  abbr      = {MLHC},
  arxiv     = {2304.05368},
  code      = {https://github.com/EternityYW/LLM_healthcare},
  poster    = {Yuqing_MLHC2023_poster.pdf},
  selected  = {true}
}

@inproceedings{wang2022predicting,
  abstract  = {As critically ill patients frequently develop anemia or coagulopathy, transfusion of blood products is a frequent intervention in the Intensive Care Units (ICU). However, inappropriate transfusion decisions made by physicians are often associated with increased risk of complications and higher hospital costs. In this work, we aim to develop a decision support tool that uses available patient information for transfusion decision-making on three common blood products (red blood cells, platelets, and fresh frozen plasma). To this end, we adopt an off-policy batch reinforcement learning (RL) algorithm, namely, discretized Batch Constrained Q-learning, to determine the best action (transfusion or not) given observed patient trajectories. Simultaneously, we consider different state representation approaches and reward design mechanisms to evaluate their impacts on policy learning. Experiments are conducted on two real-world critical care datasets: the MIMIC-III and the UCSF. Results demonstrate that policy recommendations on transfusion achieved comparable matching against true hospital policies via accuracy and weighted importance sampling evaluations on the MIMIC-III dataset. Furthermore, a combination of transfer learning (TL) and RL on the data-scarce UCSF dataset can provide up to 17.02% improvement in terms of accuracy, and up to 18.94% and 21.63% improvement in jump-start and asymptotic performance in terms of weighted importance sampling averaged over three transfusion tasks. Finally, simulations on transfusion decisions suggest that the transferred RL policy could reduce patients' estimated 28-day mortality rate by 2.74% and decreased acuity rate by 1.18% on the UCSF dataset. In short, RL with appropriate patient state encoding and reward designs shows promise in treatment recommendations for blood transfusion and further optimizes the real-time treatment strategies by improving patients' clinical outcomes.},
  title     = {Predicting the need for blood transfusion in intensive care units with reinforcement learning},
  author    = {Yuqing Wang and Yun Zhao and Linda Petzold},
  booktitle = {ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
  pages     = {1--10},
  year      = {2022},
  abbr      = {ACM-BCB},
  award     = {Best Student Paper Award},
  arxiv     = {2206.14198},
  selected  = {true}
}


